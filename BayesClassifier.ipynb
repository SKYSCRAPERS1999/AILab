{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T00:49:18.367791Z",
     "start_time": "2018-09-25T00:49:18.357044Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import math, re, datetime, random\n",
    "import pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T07:15:47.156115Z",
     "start_time": "2018-09-25T07:15:47.144647Z"
    }
   },
   "outputs": [],
   "source": [
    "def rescaling(x, d1, d2):\n",
    "    if (x <= d1):\n",
    "        return 'small'\n",
    "    elif (x <= d2):\n",
    "        return 'mid'\n",
    "    else:\n",
    "        return 'big'\n",
    "     \n",
    "def get_data3(ratio = 0.8):\n",
    "    data = pd.read_csv('./data3.csv')\n",
    "    data['好瓜'] = data['好瓜'].apply(lambda x: True if x == '是' else False)\n",
    "    data = data.drop(axis=1,columns=['编号'])\n",
    "    feature_rescale = ['含糖率', '密度']\n",
    "    for fea in feature_rescale:\n",
    "        sorted_feature_data = sorted(list(data[fea]))\n",
    "        n = len(sorted_feature_data)\n",
    "        data[fea] = data[fea].apply(rescaling,d1=sorted_feature_data[n//3],d2=sorted_feature_data[2*n//3])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T07:18:44.630539Z",
     "start_time": "2018-09-25T07:18:44.621331Z"
    }
   },
   "outputs": [],
   "source": [
    "class Naive_Bayes():\n",
    "    def __init__(self, data_train):\n",
    "        from collections import defaultdict\n",
    "        self.data_train = data_train\n",
    "        self.c0 = len(data_train[data_train[data_train.columns[-1]] == False])\n",
    "        self.c1 = len(data_train[data_train[data_train.columns[-1]] == True])\n",
    "        self.table = ({}, {})\n",
    "        \n",
    "    def fit(self):\n",
    "        cols = self.data_train.columns\n",
    "        self.table[0][cols[-1]] = (self.c0 + 1) / (self.c0 + self.c1 + 2)\n",
    "        self.table[1][cols[-1]] = (self.c1 + 1) / (self.c0 + self.c1 + 2)\n",
    "        \n",
    "        for fea in cols[:-1]:\n",
    "            fea_dic = [{}, {}]\n",
    "            groups = self.data_train.groupby(axis = 0, by = fea)\n",
    "            N = len(groups)\n",
    "            \n",
    "            fea_dic[0] = defaultdict(lambda: 1 / float(self.c0 + N))\n",
    "            fea_dic[1] = defaultdict(lambda: 1 / float(self.c1 + N))\n",
    "            \n",
    "            for (val, tab) in groups:\n",
    "                n0, n1 = len(tab[tab[tab.columns[-1]] == False]), len(tab[tab[tab.columns[-1]] == True])\n",
    "                fea_dic[0][val] = (n0 + 1) / float(self.c0 + N)\n",
    "                fea_dic[1][val] = (n1 + 1) / float(self.c1 + N)\n",
    "            \n",
    "            (self.table[0][fea], self.table[1][fea]) = fea_dic\n",
    "    \n",
    "    def test(self, sample):\n",
    "        cols = self.data_train.columns\n",
    "        logl = np.zeros(2)\n",
    "        for c in range(2):\n",
    "            logl[c] += np.log(self.table[c][cols[-1]])\n",
    "            for fea in cols[:-1]:\n",
    "                val = sample[fea]\n",
    "                logl[c] += np.log(self.table[c][fea][val])\n",
    "        output = [sample[-1], logl[1] >= logl[0], (logl[0], logl[1])]\n",
    "        print ('{}, {} <-- {} '.format(output[0], output[1], output[2]))\n",
    "        \n",
    "        return output[0] == output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T07:18:46.667738Z",
     "start_time": "2018-09-25T07:18:46.657202Z"
    }
   },
   "outputs": [],
   "source": [
    "class AODE_Bayes():\n",
    "    def __init__(self, data_train):\n",
    "        from collections import defaultdict\n",
    "        self.data_train = data_train\n",
    "        self.c = (len(data_train[data_train[data_train.columns[-1]]==False]), \\\n",
    "                  len(data_train[data_train[data_train.columns[-1]]==True]))\n",
    "        self.ctable = ({}, {})\n",
    "        self.table = ({}, {})\n",
    "        \n",
    "    def fit(self):\n",
    "        cols = self.data_train.columns\n",
    "        \n",
    "        for C in range(2):\n",
    "            \n",
    "            data = self.data_train[self.data_train[cols[-1]] == (True if C == 1 else False)]\n",
    "            \n",
    "            for par in cols[:-1]:\n",
    "                groups_par = data.groupby(axis = 0, by = par)\n",
    "                N = len(groups_par)\n",
    "                par_dic = defaultdict(lambda: 1 / float(self.c[0] + self.c[1] + 2 * N))\n",
    "                self.table[C][par] = {}\n",
    "                \n",
    "                for (val, data_par) in groups_par:\n",
    "                    NC = len(data_par)\n",
    "                    par_dic[val] = (NC + 1) / float(self.c[0] + self.c[1] + 2 * N)\n",
    "                    self.table[C][par][val] = {}\n",
    "                    \n",
    "                    for son in cols[:-1]:\n",
    "                        if (son == par): \n",
    "                            continue\n",
    "                        else:\n",
    "                            groups_son = data_par.groupby(axis = 0, by = son)\n",
    "                            n = len(groups_son)\n",
    "                            son_dic = defaultdict(lambda: 1 / float(NC + n))\n",
    "                            for (ual, data_son) in groups_son:\n",
    "                                nC = len(data_son)\n",
    "                                son_dic[ual] = (nC + 1) / (NC + n)\n",
    "                        self.table[C][par][val][son] = son_dic\n",
    "            \n",
    "                self.ctable[C][par] = par_dic\n",
    "            \n",
    "    def test(self, sample):\n",
    "        cols = data_train.columns\n",
    "        logl = np.zeros(2)\n",
    "        for C in range(2):\n",
    "            for par in cols[:-1]:\n",
    "                val = sample[par]\n",
    "                if par not in self.table[C] or val not in self.table[C][par]: continue    \n",
    "                p = self.ctable[C][par][val]\n",
    "                for son in cols[:-1]:\n",
    "                    if son == par: continue\n",
    "                    ual = sample[son]\n",
    "                    if son not in self.table[C][par][val]: continue\n",
    "#                         print('par, val, son, ual = ({},{},{},{})'.format(par,val,son,ual))\n",
    "                    p *= self.table[C][par][val][son][ual]\n",
    "                logl[C] += p\n",
    "        \n",
    "        output = [sample[-1], logl[1] >= logl[0], (logl[0], logl[1])]\n",
    "        print ('{}, {} <-- {} '.format(output[0], output[1], output[2]))\n",
    "        \n",
    "        return output[0] == output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T07:19:41.015392Z",
     "start_time": "2018-09-25T07:19:40.501590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True, True <-- (-9.424027696633352, -6.409084615258397) \n",
      "True, True <-- (0.009127126293838538, 0.1039831390653319) \n",
      "True, True <-- (-9.934853320399345, -7.033238924331391) \n",
      "True, True <-- (0.013046840658126965, 0.12406379614193605) \n",
      "True, True <-- (-9.999391841536916, -5.451971888863987) \n",
      "True, True <-- (0.015923203906609656, 0.06963178372431475) \n",
      "True, True <-- (-9.934853320399345, -6.74555685187961) \n",
      "True, True <-- (0.01063625971650663, 0.10324877126949683) \n",
      "True, True <-- (-9.488566217770924, -6.368262620738142) \n",
      "True, True <-- (0.015849590741226362, 0.12746183156834975) \n",
      "True, True <-- (-9.249674309488576, -7.844169140547719) \n",
      "True, True <-- (0.009172010876290661, 0.06662907900865361) \n",
      "True, False <-- (-8.84420920138041, -9.412785058461566) \n",
      "True, True <-- (0.009774676400600662, 0.20095530684057483) \n",
      "True, True <-- (-8.977740594004933, -6.773727728846306) \n",
      "True, True <-- (0.012606073398720018, 0.06741426172807047) \n",
      "False, False <-- (-8.220054892307417, -9.923610682227556) \n",
      "False, False <-- (0.04100403825039061, 0.03131964203555818) \n",
      "False, False <-- (-10.048182005706348, -12.785811563157024) \n",
      "False, False <-- (0.036701590953074736, 0.008718488804539529) \n",
      "False, False <-- (-8.28459341344499, -15.40424960556955) \n",
      "False, False <-- (0.03514092250882277, 0.003571468509572374) \n",
      "False, False <-- (-8.04570150516264, -12.513877847673383) \n",
      "False, False <-- (0.02955936728814237, 0.011237680794271546) \n",
      "False, True <-- (-8.977740594004933, -7.466874909406251) \n",
      "False, False <-- (0.040122571273370794, 0.018148196863523817) \n",
      "False, False <-- (-8.690058521553151, -9.51814557411939) \n",
      "False, False <-- (0.050748891504693416, 0.019739795603985456) \n",
      "False, True <-- (-9.537356381940356, -7.844169140547719) \n",
      "False, True <-- (0.023735418656880083, 0.05342108044267387) \n",
      "False, False <-- (-7.996911340993208, -11.155754363520188) \n",
      "False, False <-- (0.03131877590540928, 0.020317515452022553) \n",
      "False, False <-- (-8.155516371169847, -9.741289125433601) \n",
      "False, False <-- (0.02501235578959368, 0.01878921507267503) \n",
      "test_accracy 1: 0.8235294117647058\n",
      "test_accracy 2: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "data_train = get_data3()\n",
    "nb = Naive_Bayes(data_train)\n",
    "nb.fit()\n",
    "snb = AODE_Bayes(data_train)\n",
    "snb.fit()\n",
    "\n",
    "acc1, acc2, n = 0.0, 0.0, len(data_train)\n",
    "for i in range(n):\n",
    "    sample_test = data_train.iloc[i]\n",
    "    acc1 += nb.test(sample_test)\n",
    "    acc2 += snb.test(sample_test)\n",
    "\n",
    "print ('test_accracy 1: {}'.format(acc1 / float(n)))\n",
    "print ('test_accracy 2: {}'.format(acc2 / float(n)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
